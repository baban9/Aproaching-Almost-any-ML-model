{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_predictions(probas):\n",
    "    return np.mean(probas, axis=1) \n",
    "\n",
    "def max_voting(preds):\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "    return np.take_along_axis(preds, idxs[:, None], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5 2.5 1. ]\n",
      "[2.5 1.  2.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.5 , 1.75, 1.75])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank_mean(probas):\n",
    "    ranked = [] \n",
    "    for i in range(probas.shape[1]):\n",
    "        rank_data = stats.rankdata(probas[:,i])\n",
    "        print(rank_data)\n",
    "        ranked.append(rank_data) \n",
    "\n",
    "    ranked = np.column_stack(ranked)\n",
    "    return np.mean(ranked, axis=1)\n",
    "\n",
    "rank_mean(np.array([[1,1],[1,0],[0,1]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we train our random forest model, logistic regression model and our xgboost model on fold 1 and make predictions on fold 2. \n",
    "\n",
    "After this, we train the models from scratch on fold 2 and make predictions on fold 1. \n",
    "\n",
    "Thus, we have created predictions for all of the training data. \n",
    "\n",
    "-----------\n",
    "Now to combine these models\n",
    "we take fold 1 and all the predictions for fold 1 and create an optimization function that tries to find the best weights so as to minimize error or maximize AUC against the targets for fold 2. \n",
    "\n",
    "So, we are kind of training an optimization model on fold 1 with the\n",
    "predicted probabilities for the three models and evaluating it on fold 2. \n",
    "\n",
    "Let’s first look at a class we can use to find the best weights of multiple models to optimize for AUC (or any kind of prediction-metric combination in general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizeAUC:\n",
    "    def __init__(self):\n",
    "        self.coef = 0.0 \n",
    "\n",
    "    def _auc(self, coef, X, y):\n",
    "        x_coef = X * coef\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        auc_score = metrics.roc_auc_score(y, predictions)\n",
    "        return -1.0 * auc_score\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._auc, X=X, y=y) \n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size=1)\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split(\n",
    " X,\n",
    " y,\n",
    " test_size=0.5,\n",
    " stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(xfold1, yfold1)\n",
    "rf.fit(xfold1, yfold1)\n",
    "xgbc.fit(xfold1, yfold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logreg = logreg.predict_proba(xfold2)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold2)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-2: LR AUC = 0.9560274566795376\n",
      "Fold-2: RF AUC = 0.9744605232231535\n",
      "Fold-2: XGB AUC = 0.9744113231523053\n",
      "Fold-2: Average Pred AUC = 0.9756911649952775\n"
     ]
    }
   ],
   "source": [
    "fold2_preds = np.column_stack((\n",
    " pred_logreg,\n",
    " pred_rf,\n",
    " pred_xgbc,\n",
    " avg_pred\n",
    "))\n",
    "\n",
    "# calculate and store individual AUC values\n",
    "aucs_fold2 = []\n",
    "for i in range(fold2_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i])\n",
    "    aucs_fold2.append(auc)\n",
    "\n",
    "print(f\"Fold-2: LR AUC = {aucs_fold2[0]}\")\n",
    "print(f\"Fold-2: RF AUC = {aucs_fold2[1]}\")\n",
    "print(f\"Fold-2: XGB AUC = {aucs_fold2[2]}\")\n",
    "print(f\"Fold-2: Average Pred AUC = {aucs_fold2[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "logreg.fit(xfold2, yfold2)\n",
    "rf.fit(xfold2, yfold2)\n",
    "xgbc.fit(xfold2, yfold2)\n",
    "pred_logreg = logreg.predict_proba(xfold1)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold1)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold1)[:, 1]\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3\n",
    "fold1_preds = np.column_stack((\n",
    " pred_logreg,\n",
    " pred_rf,\n",
    " pred_xgbc,\n",
    " avg_pred\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1: LR AUC = 0.9534254807692307\n",
      "Fold-1: RF AUC = 0.9722848890493159\n",
      "Fold-1: XGB AUC = 0.9714193668335791\n",
      "Fold-1: Average prediction AUC = 0.9725149696383223\n"
     ]
    }
   ],
   "source": [
    "aucs_fold1 = []\n",
    "for i in range(fold1_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i])\n",
    "    aucs_fold1.append(auc)\n",
    "print(f\"Fold-1: LR AUC = {aucs_fold1[0]}\")\n",
    "print(f\"Fold-1: RF AUC = {aucs_fold1[1]}\")\n",
    "print(f\"Fold-1: XGB AUC = {aucs_fold1[2]}\")\n",
    "print(f\"Fold-1: Average prediction AUC = {aucs_fold1[3]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find model weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = OptimizeAUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.973388\n",
      "         Iterations: 39\n",
      "         Function evaluations: 83\n",
      "Optimized AUC, Fold 2 = 0.9760217254712846\n",
      "Coefficients = [0.0652288  0.14094025 0.50889822]\n"
     ]
    }
   ],
   "source": [
    "opt.fit(fold1_preds[:, :-1], yfold1)\n",
    "opt_preds_fold2 = opt.predict(fold2_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold2, opt_preds_fold2)\n",
    "print(f\"Optimized AUC, Fold 2 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.976218\n",
      "         Iterations: 65\n",
      "         Function evaluations: 137\n",
      "Optimized AUC, Fold 1 = 0.9731967313836324\n",
      "Coefficients = [0.15688259 0.20408024 0.47410531]\n"
     ]
    }
   ],
   "source": [
    "opt = OptimizeAUC()\n",
    "opt.fit(fold2_preds[:, :-1], yfold2)\n",
    "opt_preds_fold1 = opt.predict(fold1_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold1, opt_preds_fold1)\n",
    "print(f\"Optimized AUC, Fold 1 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
